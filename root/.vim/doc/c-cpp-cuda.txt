vim:ft=help
*c-cpp-cuda*

======================================================================================
LLVM Toolchains

--------------------------------------------------------------------------------------
*clangd*

用户全局配置文件: `~/.config/clangd/config.yaml`

项目目录 compile_flags.txt

clangd设置`compile_commands.json`文件位置为`build/release/compile_commands.json`

`.clangd`文件中添加

See: https://www.reddit.com/r/neovim/comments/vj0e16/how_to_specify_location_of_compile_commandsjson/
>
	CompileFlags:
	  CompilationDatabase: build/       # Search build/ directory for compile_commands.json
<
同时clangd启动命令添加`--compile-commands-dir=build/release`

--------------------------------------------------------------------------------------
Clangd 配置问题

clangd无法解析OpenMP pragma https://github.com/clangd/clangd/issues/1640
暂时的解决方案：在`.clangd`文件中添加
>yaml
    CompileFlags:
      Remove: [-fopenmp]
<
clangd还没实现outgoing calls in call hierarchy https://github.com/llvm/llvm-project/pull/77556

clangd omp.h not found ~

locate /omp.h 找到omp.h文件位置，然后在`.clangd`文件中添加
>yaml
    CompileFlags:
      Add:
        - -isystem/usr/lib/gcc/x86_64-linux-gnu/13/include/
<

clangd / |ccls| 找不到c++系统头文件解决方法 ~

安装当前系统最新的libstdc++

>
	apt search libstdc++
	apt install libstdc++-12-dev
<

https://stackoverflow.com/questions/74785927/clangd-doesnt-recognize-standard-headers

查看当前系统安装的libstdc++版本
>
	ls /usr/include/c++
<
clang: In included file: use of undeclared identifier '__builtin_ia32_prefetch' 解决方法 ~

由于编译器未启用特定的处理器架构或指令集支持所致。这个内建函数是用于 x86
平台的特定指令。如果没有正确设置目标架构，编译器可能无法识别这些内建函数。

方法一：添加编译选项
>yaml
    CompileFlags:
      Add: [-march=x86-64]
<

方法二：添加头文件
>cpp
    #include <xmmintrin.h>
<
--------------------------------------------------------------------------------------

*clang-format* `:%!clang-format` or `:'<,'>!clang-format`.
No need of `Plug 'rhysd/vim-clang-format'`

*clang-tidy*
output to quickfix list: >
  :CExprsys clang-tidy hello.cpp
<

*Makefile*

= 延迟赋值，使用到变量的时候才确定变量的值
:= 立即赋值

======================================================================================
Ccls

Oceanbase uses ccls https://github.com/oceanbase/oceanbase/blob/ed4ed014ef2f2a904c64e04331ac4dc1ccf2b778/docs/ide-settings.md

In the C/C++ LSP domain, the famous tools are clangd and ccls. Here we recommend ccls, because:

- The speed of building index of ccls is slower than that of clangd, but after building, the speed of accessing index of ccls is faster than that of clangd.
- Unity building doesn't be supported by clangd, but OceanBase is being built by unity, failed to build index through compile_commands.json by clangd.

======================================================================================
CCache

*ccache*
>bash
    # Ccache设置目录
    export CCACHE_DIR=<path-to-your-cache-directory>
    # 设置缓存大小
    ccache -M 50G
<

CMake设置CCache ~
>cmake
    find_program(CCACHE_PROGRAM ccache)
    if(CCACHE_PROGRAM)
        set(CMAKE_CXX_COMPILER_LAUNCHER "${CCACHE_PROGRAM}")
        set(CMAKE_CUDA_COMPILER_LAUNCHER "${CCACHE_PROGRAM}") # CMake 3.9+
    endif()
<
======================================================================================
C++ Build & Package Management Tools

*ninja*

改变控制台输出状态。
>bash
	export NINJA_STATUS="[%r processes, %f/%t @ %o/s | %e sec]"
<

列出所有targets: `ninja -t targets`

*cmake*

教程
https://cliutils.gitlab.io/modern-cmake/README.html

>bash
    pip install cmake-language-server cmakelang
<

CMake 4种编译类型 ~

Debug, Release, RelWithDebInfo, MinSizeRel

https://cmake.org/cmake/help/latest/variable/CMAKE_BUILD_TYPE.html

CMake 显示编译命令 ~

Makefile: 添加 `set(CMAKE_VERBOSE_MAKEFILE ON)` 或者
>bash
	cmake -DCMAKE_VERBOSE_MAKEFILE=ON ..
<

或者
>bash
	make VERBOSE=1
<

Ninja:
>bash
	cmake -DCMAKE_VERBOSE_MAKEFILE=ON -G Ninja ..
	ninja -v
<

调试CMake ~

输出 CMake 执行的每一步操作，适用于需要详细调试信息的场景。
>bash
	cmake --trace --trace-expand ..
<

CMake导出compile_commands.json ~
>bash
    cmake -DCMAKE_EXPORT_COMPILE_COMMANDS=ON ..
<

CMake不使用response file ~

CUDA的include flag放在response file中，用`--options-file`参数表示。低版本的clangd 16.0.6无法正确解析`--options-file`
https://github.com/llvm/llvm-project/blame/80e61e38428964c9c9abac5b7a59bb513b5b1c3d/clang/lib/Driver/ToolChains/Cuda.cpp#L506

以CUDA为例。set()需要放在project()后面。
>cmake
    project(AlgorithmInCuda LANGUAGES CXX CUDA)

    # put these lines after project() to avoid response file
    # See:
    # https://github.com/clangd/clangd/issues/81#issuecomment-546618695
    # https://github.com/search?q=repo%3AKitware%2FCMake+RESPONSE_FILE&type=code
    # https://stackoverflow.com/questions/67928865/how-to-force-cmake-to-use-a-response-file-when-linking-cuda-on-windows
    set(CMAKE_CUDA_USE_RESPONSE_FILE_FOR_INCLUDES 0)
    set(CMAKE_CUDA_USE_RESPONSE_FILE_FOR_LIBRARIES 0)
    set(CMAKE_CUDA_USE_RESPONSE_FILE_FOR_OBJECTS 0)
<
--------------------------------------------------------------------------------------

*CPM.cmake* https://github.com/cpm-cmake/CPM.cmake

使用项目：rapidsai/RAFT

*conan1*

使用项目：milvus

~/.conan/conan.conf 改存储路径，节省硬盘空间
>
    [storage]
    # This is the default path, but you can write your own. It must be an absolute path or a
    # path beginning with "~" (if the environment var CONAN_USER_HOME is specified, this directory, even
    # with "~/", will be relative to the conan user home, not to the system user home)
    path = /usr3/jiangyinzuo_data/conan_data
<

*bazel*

使用项目：HA3

*conan2*

*vcpkg*

*xmake*

|conda|

使用项目：rapidsai/RAFT

--------------------------------------------------------------------------------------
*c++20-module*

Error:
target contains C++ module sources which are not supported by the generator

Solution:
默认的make换为Ninja

Error:
CMAKE_CXX_COMPILER_CLANG_SCAN_DEPS-NOTFOUND: not found

Solution:
手动添加CMAKE_CXX_COMPILER_CLANG_SCAN_DEPS
set(CMAKE_CXX_COMPILER_CLANG_SCAN_DEPS clang-scan-deps-17)

apt安装最新 *gnu-toolchain*
https://launchpad.net/~ubuntu-toolchain-r/+archive/ubuntu/test

安装最新 *llvm-toolchain*
https://apt.llvm.org/

在Ubuntu 18.04中，可以添加apt源
>
	deb http://apt.llvm.org/bionic/ llvm-toolchain-bionic main
	deb-src http://apt.llvm.org/bionic/ llvm-toolchain-bionic main
	# Needs 'sudo add-apt-repository ppa:ubuntu-toolchain-r/test' for libstdc++ with C++20 support
	# 16
	deb http://apt.llvm.org/bionic/ llvm-toolchain-bionic-16 main
	deb-src http://apt.llvm.org/bionic/ llvm-toolchain-bionic-16 main
	# 17
	deb http://apt.llvm.org/bionic/ llvm-toolchain-bionic-17 main
	deb-src http://apt.llvm.org/bionic/ llvm-toolchain-bionic-17 main
<

添加gpg key
>
	wget -O - https://apt.llvm.org/llvm-snapshot.gpg.key | sudo apt-key add -
<

====================================================================================
*cuda*

https://docs.nvidia.com/cuda/cuda-c-programming-guide/
https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/

|nvidia-docker|

cuda对gcc/clang存在版本要求，例如

cuda 12.1
>
	clang version must be less than 16 and greater than 3.2 for cuda 12.1
	gcc versions later than 12 are not supported for cuda 12.1
<

安装CUDA  ~

https://developer.nvidia.com/cuda-toolkit-archive

第一类方法： `apt install nvidia-cuda-toolkit`，安装后nvcc位于 `/usr/bin/nvcc`
第二类方法：添加apt源后 `apt install cuda`，安装后nvcc位于 `/usr/local/cuda-X-Y/bin/nvcc`
第三类方法： 下载runfile安装。

卸载CUDA ~

https://docs.nvidia.com/cuda/archive/11.8.0/cuda-installation-guide-linux/index.html#handle-uninstallation

GPU监控 ~

*gpustat* `pip install gpustat`
*nvtop*
*nvitop* `pip install nvitop`

【工具篇】如何优雅地监控显卡(GPU)使用情况？ - 聚丙烯酰胺的文章 - 知乎 https://zhuanlan.zhihu.com/p/577533593

运行CUDA程序时，限定使用哪些GPU ~

默认使用GPU 0
>bash
    # 仅使用GPU 0和2
    CUDA_VISIBLE_DEVICES=0,2 python your_script.py
    # 仅使用GPU 1
    CUDA_VISIBLE_DEVICES=1 python3 -m cuvs_bench.run --algorithms cuvs_cagra --dataset=gist-960-euclidean --dataset-path=/home/jiangyinzuo/cuvs/datasets -bs 10
    # 完全禁用GPU
    CUDA_VISIBLE_DEVICES= python your_script.py
<
------------------------------------------------------------------------------------
CUDA 编程常见错误

an illegal memory access was encountered: 显存OOM了，检查有没有显存忘记释放

invalid argument: 调用核函数时传递的参数有问题（shared memory、block size等参数过大或非法）

------------------------------------------------------------------------------------
Failed to initialize NVML: Driver/library version mismatch NVML library version: 535.183

原因：kernel mod 的 Nvidia driver 的版本没有更新
解决方法：重启服务器

https://comzyh.com/blog/archives/967/

*cuda-gdb*

帮助 `help cuda`
查看cuda线程 `info cuda threads`
查看当前cuda线程 `cuda thread`
切换到cuda线程2 `cuda thread 2`

====================================================================================
*glibc*

查看glibc版本
>
	ldd --version
<
CentOS7.1 2.18
Ubuntu18.04 为2.27

许多软件依赖2.28

**gcc版本**
2024年初，CentOS 7.1: 4.8.5
Ubuntu 16.04: 5.4.0
======================================================================================
*cpp-mistakes*

使用std::copy拷贝std::vector，而非memcpy
